# NPL

Mini-proyecto de procesamiento de texto utilizando t茅cnicas cl谩sicas

# Integrantes

Jonathan Pacheco

Joshua Triana

Julio Morales

# Proyecto Final crear tu propio ChatGPT usando un RAG

#  Retrieval-Augmented Generation (RAG) con Ollama y Langchain

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/jopachecoc/NPL/blob/main/PF_ChatGPT_RAG.ipynb) PF_ChatGPT_RAG.ipynb

---

# PF_ChatGPT_RAG: Retrieval-Augmented Generation con Ollama y Langchain

Este notebook implementa un sistema de RAG (Retrieval-Augmented Generation) usando modelos pre-entrenados, Ollama y LangChain, sobre un corpus de noticias en espa帽ol. El objetivo es crear un chatbot capaz de responder preguntas utilizando informaci贸n recuperada de los documentos.

## Ejecuci贸n en Google Colab

Puedes ejecutar el notebook directamente en Google Colab usando el siguiente enlace:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jopachecoc/NPL/blob/main/PF_ChatGPT_RAG.ipynb)

## Requisitos

- GPU recomendada (T4 o superior)
- El notebook instala autom谩ticamente las dependencias necesarias (Ollama, LangChain, FAISS, Gradio, etc.)

## Pasos principales del notebook

1. Instalaci贸n de dependencias y configuraci贸n de entorno
2. Carga y exploraci贸n del dataset de noticias en espa帽ol
3. Indexaci贸n de documentos con FAISS y generaci贸n de embeddings
4. Configuraci贸n de Ollama y LangChain para el modelo LLM
5. Implementaci贸n de la cadena de recuperaci贸n y generaci贸n de respuestas
6. Interfaz conversacional con Gradio

## Notas

- No se requiere entrenamiento de modelos, solo se usan modelos pre-entrenados.
- El corpus utilizado puede ser modificado, pero debe mantener una estructura similar.
- El historial de conversaci贸n se maneja tanto en LangChain como en la interfaz de usuario.

## Referencias

- [LangChain](https://www.langchain.com)
- [Ollama](https://ollama.com)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Gradio](https://gradio.app)

## Evidencias de ejecuci贸n

A continuaci贸n se muestran ejemplos de la ejecuci贸n del notebook `PF_ChatGPT_RAG.ipynb` en Google Colab, donde se observa el funcionamiento del chatbot con RAG y LangChain:

### Ejemplo 1: Inicio y carga del sistema

![Evidencia 1: Inicio y carga del sistema](IMG1ChB1.jpg)

---

### Ejemplo 2: Pregunta al chatbot y recuperaci贸n de contexto

![Evidencia 2: Pregunta al chatbot y recuperaci贸n de contexto](IMG1ChB2.jpg)

---

### Ejemplo 3: Respuesta generada y referencias a documentos

![Evidencia 3: Respuesta generada y referencias a documentos](IMG1ChB3.jpg)

---

## Estas im谩genes muestran el flujo completo: desde la carga del sistema, la interacci贸n con el chatbot, hasta la generaci贸n de respuestas con referencias a los documentos recuperados del corpus.

# ENTREGA_3: Clasificaci贸n de Texto en Espa帽ol con BERT y Hugging Face

En esta entrega se implementa un clasificador de texto en espa帽ol utilizando modelos pre-entrenados tipo BERT y la librer铆a Hugging Face Transformers. El objetivo es especializar un modelo BERT en tareas de clasificaci贸n de sentimientos y noticias, aprovechando transfer learning y fine-tuning.

## Flujo de trabajo

1. **Carga y an谩lisis exploratorio de datasets**

   - Uso de datasets de Hugging Face como `pysentimiento/spanish-tweets` y `tweet_eval`.
   - Estad铆sticas de longitud y distribuci贸n de clases.

2. **Preprocesamiento y tokenizaci贸n**

   - Uso del tokenizador oficial del modelo BERT en espa帽ol ([dccuchile/bert-base-spanish-wwm-cased](https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased)).
   - Conversi贸n de textos a secuencias de tokens y m谩scaras de atenci贸n.

3. **Preparaci贸n de datos**

   - Divisi贸n en conjuntos de entrenamiento, validaci贸n y prueba.
   - Conversi贸n de etiquetas a IDs.

4. **Definici贸n y ajuste del modelo**

   - Uso de `AutoModelForSequenceClassification` de Hugging Face.
   - Entrenamiento como featurizer (congelando BERT) y fine-tuning (entrenando todo el modelo).
   - Experimentaci贸n con diferentes cabezas de clasificaci贸n.

5. **Entrenamiento y evaluaci贸n**
   - Entrenamiento con la clase `Trainer` de Hugging Face.
   - Monitoreo con TensorBoard.
   - Evaluaci贸n de precisi贸n y an谩lisis de errores.

## Resultados

- Precisi贸n superior al 90% en el conjunto de prueba usando fine-tuning.
- El uso de modelos pre-entrenados reduce el tiempo de entrenamiento y mejora la calidad respecto a modelos desde cero.

## Datasets utilizados

- pysentimiento/spanish-tweets'

## Ejecuci贸n

Puedes ejecutar el notebook [tercera_entrega.ipynb](tercera_entrega.ipynb) localmente o en Google Colab:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jopachecoc/NPL/blob/main/tercera_entrega.ipynb)

# ENTREGA 2: Clasificaci贸n de Noticias en Espa帽ol con LSTM

Este proyecto implementa un clasificador de noticias en espa帽ol utilizando una red neuronal LSTM (Long Short-Term Memory) con PyTorch Lightning. El objetivo es categorizar titulares de noticias en cinco categor铆as: Deportes, Salud, Tecnolog铆a, Colombia y Econom铆a.

## Descripci贸n

Se utiliza un dataset de noticias reales del portal RCN, disponible en [Hugging Face Hub](https://huggingface.co/datasets/Nicky0007/titulos_noticias_rcn_clasificadas). El flujo de trabajo incluye:

1. **Carga y an谩lisis exploratorio del dataset**

   - Estad铆sticas de longitud de los textos.
   - Distribuci贸n de clases.

2. **Preprocesamiento y tokenizaci贸n**

   - Tokenizador simple y construcci贸n de vocabulario.
   - Conversi贸n de textos a secuencias de tokens.

3. **Preparaci贸n de datos**

   - Divisi贸n en conjuntos de entrenamiento, validaci贸n y prueba.
   - Balanceo de clases.

4. **Definici贸n del modelo**

   - Implementaci贸n de un bloque LSTM y una capa densa para clasificaci贸n.
   - Entrenamiento con PyTorch Lightning.

5. **Entrenamiento y evaluaci贸n**

   - Ajuste de hiperpar谩metros.
   - Monitoreo con TensorBoard.
   - Evaluaci贸n de precisi贸n global y por clase.

6. **Resultados**
   - Precisi贸n general superior al 90%.
   - An谩lisis de errores y recomendaciones para mejorar la clase "Colombia".

## Requisitos

- Python 3.10+
- PyTorch
- PyTorch Lightning
- datasets
- matplotlib
- scikit-learn
- numpy
- pandas

Instala las dependencias con:

```sh
pip install -r requerimientos.txt
```

## Ejecuci贸n

Puedes ejecutar el notebook [segundo_entrega.ipynb](segundo_entrega.ipynb) localmente o en Google Colab:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ohtar10/icesi-nlp/blob/main/Sesion2/2-nlp-with-lstm.ipynb)

## Notas

- El modelo utiliza una longitud m谩xima de 35 tokens por texto, optimizada seg煤n la distribuci贸n del dataset.
- Se emplea el estado oculto final de la LSTM como representaci贸n del texto.
- El c贸digo est谩 preparado para facilitar la experimentaci贸n y el ajuste de hiperpar谩metros.

## Resultados

- Precisi贸n global: ~90%
- Precisi贸n por clase: superior al 91% en la mayor铆a de categor铆as, con margen de mejora en "Colombia".

## Aplicaciones

- Clasificaci贸n autom谩tica de noticias en portales de contenido.
- Organizaci贸n y personalizaci贸n de la experiencia del usuario.

---
